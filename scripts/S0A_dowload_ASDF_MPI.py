#!/usr/bin/env python
"""
This script:
    1) downloads sesimic data located in a broad region defined by user or using a pre-compiled station list;
    2) cleans up raw traces by removing gaps, instrumental response, downsampling and trimming to a day length;
    3) saves data into ASDF format (see Krischer et al., 2016 for more details on the data structure);
    4) parallelize the downloading processes with MPI.
    5) avoids downloading data for stations that already have 1 or 3 channels

Authors: Chengxin Jiang (chengxin_jiang@fas.harvard.edu)
         Marine Denolle (mdenolle@fas.harvard.edu)

NOTE:
    0. MOST occasions you just need to change parameters followed with detailed explanations to run the script.
    1. to avoid segmentation fault later in cross-correlation calculations due to too large data in memory,
    a rough estimation of the memory needs is made in the beginning of the code. you can reduce the value of
    inc_hours if memory on your machine is not enough to load proposed (x) hours of noise data all at once;
    2. if choose to download stations from an existing CSV files, stations with the same name but different
    channel is regarded as different stations (same format as those generated by the S0A);
    3. for unknow reasons, including station location code during feteching process sometime result in no-data.
    Therefore, we recommend setting location code to "*" in the request setting (L105 & 134) when it is confirmed
    manually by the users that no stations with same name but different location codes occurs.

Enjoy the NoisePy journey!
"""

import sys
from time import time
import os, glob

from mpi4py import MPI
import numpy as np
from obspy import UTCDateTime
from obspy.clients.fdsn import Client
from obspy.clients.fdsn.header import FDSNNoDataException
import pandas as pd
import pyasdf

from noisepy import noise_module

if not sys.warnoptions:
    import warnings

    warnings.simplefilter("ignore")

#########################################################
################ PARAMETER SECTION ######################
#########################################################

# paths and filenames
ROOT_PATH = os.path.abspath("./NoisePy_example")
# downloaded data stored here
DL_PATH = os.path.join(ROOT_PATH, "RAW_DATA")
# if this exists, use manually specified available station information
# otherwise store the same information with the download data
dlist = os.path.join(ROOT_PATH, "station.txt")
# store parameters here
metadata = os.path.join(DL_PATH, "download_info.txt")

# list of shortcuts: https://docs.obspy.org/packages/obspy.clients.fdsn.html
SERVER = "SCEDC"

samp_freq = 20  # targeted sampling rate at X samples per seconds
rm_resp = "no"  # select 'no' to not remove response and use 'inv','spectrum','RESP', or 'polozeros' to remove response
respdir = os.path.join(
    ROOT_PATH, "resp"
)  # directory where resp files are located (required if rm_resp is neither 'no' nor 'inv')
freqmin = 0.05  # pre filtering frequency bandwidth
freqmax = 2  # note this cannot exceed Nquist freq

# targeted region/station information: only needed when not using dlist
lamin = 32.5
lamax = 36.0
lomin = -121.0
lomax = -114.0
# list of wanted station parameters when downloading
# when not using dlist, TODO: why not HH1, HH2 and rotate to N and E?
chan_list = ["BHE", "BHN", "BHZ"]
net_list = ["CI"]
sta_list = ["*"]
# total time period
starttime = UTCDateTime("2016-07-01T00:00:00")
endtime = UTCDateTime("2016-07-02T00:00:00")
# request chunk size (hours)
inc_hours = 24
# this won't work if we have NE and 12 components
ncomp = len(chan_list)

# get rough estimate of memory needs to ensure it now below up in S1
cc_len = 1800  # basic unit of data length for fft (s)
step = 450  # overlapping between each cc_len (s)
MAX_MEM = 40.0  # maximum memory allowed per core in GB (don't think this is per core)
FLOAT_SIZE = 4

# change this but currently setup to use custom format
starttime_str = starttime.isoformat().translate({45: "_", 58: "_", 84: "_"})
endtime_str = endtime.isoformat().translate({45: "_", 58: "_", 84: "_"})
# assemble parameters used for pre-processing
# will be updated before saved
prepro_para = {
    "rm_resp": rm_resp,
    "respdir": respdir,
    "freqmin": freqmin,
    "freqmax": freqmax,
    "samp_freq": samp_freq,
    "start_date": starttime_str,
    "end_date": endtime_str,
    "inc_hours": inc_hours,
    "cc_len": cc_len,
    "step": step,
    "MAX_MEM": MAX_MEM,
    "lamin": lamin,
    "lamax": lamax,
    "lomin": lomin,
    "lomax": lomax,
    "ncomp": ncomp,
}


#######################################################
#################STATION SECTION#######################
#######################################################

tt0 = time()
client = Client(SERVER)

# prepare station info (existing station list vs. fetching from client)
if os.path.isfile(dlist):
    # read station info from list
    df = pd.read_csv(dlist)
    nsta = len(df)
    chan = df["channel"].tolist()
    net = df["network"].tolist()
    sta = df["station"].tolist()
    lat = df["latitude"].tolist()
    lon = df["longitude"].tolist()
    # location setting optional
    try:
        location = df["location"].tolist()
    except KeyError:
        location = ["*"] * nsta
    del df

else:
    # read station info from server
    nsta = 0
    chan = []
    net = []
    sta = []
    lat = []
    lon = []
    location = []
    elev = []
    # loop through specified network, station and channel lists
    for inet in net_list:
        for ista in sta_list:
            for ichan in chan_list:
                # gather station info
                try:
                    inv = client.get_stations(
                        network=inet,
                        station=ista,
                        channel=ichan,
                        location="*",
                        starttime=starttime,
                        endtime=endtime,
                        minlatitude=lamin,
                        maxlatitude=lamax,
                        minlongitude=lomin,
                        maxlongitude=lomax,
                        level="response",
                    )
                except FDSNNoDataException:
                    print("no stations found")
                    continue

                for K in inv:
                    for tsta in K:
                        sta.append(tsta.code)
                        net.append(K.code)
                        chan.append(ichan)
                        lon.append(tsta.longitude)
                        lat.append(tsta.latitude)
                        elev.append(tsta.elevation)
                        # sometimes one station has many locations and here we only get the first location
                        if tsta[0].location_code:
                            location.append(tsta[0].location_code)
                        else:
                            location.append("*")
                        nsta += 1
prepro_para["nsta"] = nsta

# rough estimation on memory needs (assume float32 dtype)
nsec_chunk = inc_hours * 3600
nseg_chunk = int(np.floor((nsec_chunk - cc_len) / step)) + 1
npts_chunk = int(nseg_chunk * cc_len * samp_freq)
memory_size = nsta * npts_chunk * FLOAT_SIZE / 1024 ** 3
if memory_size > MAX_MEM:
    raise ValueError(
        "Require %5.3fG memory but only %5.3fG provided)! Reduce inc_hours to avoid this issue!"
        % (memory_size, MAX_MEM)
    )


########################################################
#################DOWNLOAD SECTION#######################
########################################################

# --------MPI---------
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

if rank == 0:
    if not os.path.isdir(DL_PATH):
        os.makedirs(DL_PATH)

    # output station list
    if not os.path.isfile(dlist):
        # store would-be station input with download data
        dict = {
            "network": net,
            "station": sta,
            "channel": chan,
            "latitude": lat,
            "longitude": lon,
            "elevation": elev,
        }
        df = pd.DataFrame(dict)
        df.to_csv(os.path.join(DL_PATH, "station.txt"), index=False)
        del df

    # save parameters for future reference
    fout = open(metadata, "w")
    fout.write(str(prepro_para))
    fout.close()

    # get MPI variables ready
    all_chunk = noise_module.get_event_list(starttime_str, endtime_str, inc_hours)
    if len(all_chunk) < 1:
        raise ValueError(
            "Abort! no data chunk between %s and %s" % (start_date[0], end_date[0])
        )
        comm.Abort(300)
    splits = len(all_chunk) - 1
else:
    # receive from master
    splits = None
    all_chunk = None

# broadcast the variables
splits = comm.bcast(splits, root=0)
all_chunk = comm.bcast(all_chunk, root=0)
extra = splits % size

tp = 0
# MPI: loop through each time chunk
# TODO: if MPI is useful and total times are short, split by station too
for ick in range(rank, splits, size):
    s1 = UTCDateTime(all_chunk[ick])
    s2 = UTCDateTime(all_chunk[ick + 1])
    date_info = {"starttime": s1, "endtime": s2}

    # channels already exist
    num_records = np.zeros(nsta, dtype=np.int16)

    # filename of the ASDF file
    ff = os.path.join(DL_PATH, all_chunk[ick] + "T" + all_chunk[ick + 1] + ".h5")
    if not os.path.isfile(ff):
        # creates blank container so it can be appended to
        with pyasdf.ASDFDataSet(ff, mpi=False, compression="gzip-3", mode="w") as ds:
            pass
    else:
        # very dangerous, assumes that all channels will be available and previous data correct
        # works sort of like a resume function but no safeguards
        print("WARNING: resuming and making many assumptions")
        with pyasdf.ASDFDataSet(ff, mpi=False, mode="r") as rds:
            alist = rds.waveforms.list()
            for ista in range(nsta):
                tname = net[ista] + "." + sta[ista]
                if tname in alist:
                    num_records[ista] = len(rds.waveforms[tname].get_waveform_tags())

    # appending when file exists
    with pyasdf.ASDFDataSet(ff, mpi=False, compression="gzip-3", mode="a") as ds:

        # loop through each channel
        for ista in range(nsta):

            # continue when there are alreay data for sta A at day X
            if num_records[ista] == ncomp:
                # dangerous to assume
                # TODO: make sure current channel exists instead
                continue

            # get inventory for specific station
            # TODO: this was already recieved but for total time rather than time chunk
            try:
                sta_inv = client.get_stations(
                    network=net[ista],
                    station=sta[ista],
                    location=location[ista],
                    starttime=s1,
                    endtime=s2,
                    level="response",
                )
            except FDSNNoDataException as e:
                print("no results", sta[ista])
                continue

            # add the inventory for all components + all time of this tation
            try:
                ds.add_stationxml(sta_inv)
            except Exception:
                pass

            try:
                # get data
                t0 = time()
                tr = client.get_waveforms(
                    network=net[ista],
                    station=sta[ista],
                    channel=chan[ista],
                    location=location[ista],
                    starttime=s1,
                    endtime=s2,
                )
            except Exception as e:
                print(e, "for", sta[ista])
                continue

            # preprocess to clean data
            print("preprocessing", sta[ista])
            t1 = time()
            tr = noise_module.preprocess_raw(tr, sta_inv, prepro_para, date_info)
            t2 = time()
            tp += t2 - t1

            if len(tr):
                if location[ista] == "*":
                    tlocation = "00"
                else:
                    tlocation = location[ista].lower()
                new_tags = "{}_{}".format(chan[ista].lower(), tlocation)
                ds.add_waveforms(tr, tag=new_tags)

comm.barrier()
tt1 = time()
print(
    "waveform download took {:.2f}s with {:.2f}s for preprocess".format(tt1 - tt0, tp)
)
